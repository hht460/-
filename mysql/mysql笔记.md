# 索引

## 索引覆盖

对于联合索引，当查询返回字段刚好属于联合索引字段，那么此时走普通索引检索记录就不需要回表查主键索引了

# MYSQL锁

数据库锁设计初衷是为了处理并发问题

## 锁分类

全局锁、表锁、行锁

### 全局锁

对整个数据库实例加锁；mysql提供一个全局读锁方法，命令：flush tables with read lock（ftwrl）

### 表级锁

表级锁有两种：一种是表锁，一种是元数据锁（meta data lock, MDL）;

表锁：显示指定使用 lock table/unlock table

MDL锁：MDL 不需要显式使用，在访问一个表的时候会被**自动加上**；

1. 当对一个表做增删改查操作时，加MDL读锁；
2. 当对一个表结构做变更操作时，加MDL写锁；

- **读锁之间不互斥**，因此你可以有多个线程同时对一张表增删改查。

- **读写锁之间、写锁之间是互斥的**，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行

  MDL锁获取时期：

  - 显式添加begin/start...开启事务 在sql之前，此时直接拿取mdl读/写锁
  - 未加显式开启事务，直接执行sql，在执行sql语句时获取mdl读/写锁



# 普通索引、唯一索引

## 查询过程

- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

​    注：innoDB 的数据是按数据页为单位来读写的，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。

## 更新过程

1. **涉及技术：change buffer**

   ​    注：当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了（读入过程涉及磁盘随机IO访问）。在**下次查询**需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

2. **change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge；**

3. **merge触发条件：**

   - 下次查询访问到这个数据页时，将该页读入内存进行merge
   - 系统有后台线程会定期 merge
   - 数据库正常关闭（shutdown）的过程中，也会执行 merge 操作

4. **什么条件下可以使用 change buffer 呢？**

   ​    唯一索引：不适用；更新操作都要先判断这个操作是否违反唯一性约束（*判断现在表中是否已经存在 k=4 的记录*），这必须要将数据页读入内存才能判断，数据已经在内存中，直接更新更快，没必要使用change buffer；

5. **innoDB引擎插入一条数据处理流程**（*eg: insert into (4,400)* ）

   第一种情况是，**这个记录要更新的目标页在内存中**。这时，InnoDB 的处理流程如下：

   - 对于唯一索引来说，找到 3 和 5 之间的位置，**判断到没有冲突**，插入这个值，语句执行结束；
   - 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

   第二种情况是，**这个记录要更新的目标页不在内存中**。这时，InnoDB 的处理流程如下：

   - 对于唯一索引来说，需要将数据页读入内存，找到 3 和 5 之间的位置，**判断到没有冲突**，插入这个值，语句执行结束；

   - 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。

     **注：将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问；**

6. **change buffer 使用场景**

   ​    因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大;

   对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好;

7. **索引选择和实践**

   - 普通索引和唯一索引在查询能力没有差别，主要在更新操作，普通索引做了优化，建议考虑普通索引；
   - 如果更新操作后马上伴随对这条记录得查询，此时应该关闭change buffer；其它情况下change buffer能起到提升性能作用；

8. **change buffer 和redo log**

   在表上执行新增操作：*insert into t(id,k) values(id1,k1),(id2,k2);* *当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中*

   ![](C:\Users\hht\Desktop\带 change buffer 的更新过程.png)

   这条更新语句做了如下的操作（按照图中的数字顺序）：

   - Page 1 在内存中，直接更新内存；

   - Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息

   - 将上述两个动作记入 redo log 中（图中 3 和 4）。

     注：从执行过程分析，执行这条更新语句的成本很低，就是写了两处内存（page1，change buffer），然后写了一处磁盘（两次操作合在一起写了一次磁盘/redo log），而且还是顺序写的。

   接着执行查询操作：select * from t where k in (k1, k2)

   ![](C:\Users\hht\Desktop\带 change buffer 的读过程.png)

   - 读 Page 1 的时候，直接从内存返回。

     *有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。*

   - 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

   **redo log 和change buffer对比：**

   redo log 主要节省的是随机写磁盘的 IO 消耗（转成合并顺序写）；

   change buffer 主要节省的则是随机读磁盘的 IO 消耗（不立马读取磁盘数据，而是写入change buffer）。

   # 字符串字段创建索引

   ## 创建方式

   直接创建完整索引，这样可能比较占用空间；

   创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；

   前缀索引：截取字符串前几位创建索引；

   导致结果：检索时需要回表检索主键索引树，判断结果值是否相等，同时破坏覆盖索引功能；

   倒序存储，将字符串倒序，截取前几位创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；

   创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

   **倒序存储和使用 hash 字段**比较：

   相同点：都不支持范围查询；

   不同点：

   - 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 倒序字符串前缀长度应该较长，这个消耗跟额外这个 hash 字段也差不多抵消了。
   - 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数（hash函数）。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
   - 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。
